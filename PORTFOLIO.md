# First-RAG : Architecture RAG Avanc√©e & Apprentissage

Ce projet est une impl√©mentation compl√®te d'un syst√®me de **Retrieval-Augmented Generation (RAG)**. Il repr√©sente une **d√©marche d'apprentissage approfondie** visant √† ma√Ætriser les concepts cl√©s de l'IA g√©n√©rative appliqu√©e aux documents, au-del√† des simples tutoriels.


## Objectifs & Apprentissage

L'ambition principale de ce projet √©tait de d√©construire et comprendre chaque composant d'un pipeline RAG moderne, plut√¥t que d'utiliser des solutions "cl√©s en main" abstraites.

### Concepts Cl√©s Ma√Ætris√©s
√Ä travers ce d√©veloppement, j'ai explor√© et impl√©ment√© les concepts suivants :
*   **Vector Embeddings & Semantic Search** : Compr√©hension de la projection de texte en vecteurs denses (via `Sentence Transformers`) pour capturer le sens au-del√† des simples mots-cl√©s. J'ai appris comment les embeddings transforment la s√©mantique en distance math√©matique (Similarit√© cosinus).
*   **Strat√©gies de Chunking Avanc√©es** : Apprentissage des nuances entre un d√©coupage na√Øf (par caract√®res) et le **Chunking S√©mantique** (d√©couper dynamiquement l√† o√π le sens change), essentiel pour ne pas tronquer les id√©es.
*   **Indexation Avanc√©e (Parent-Child)** : Mise en ≈ìuvre du pattern **Parent-Child Indexing** pour d√©coupler "ce qu'on cherche" (petits fragments pr√©cis pour le vecteur) de "ce qu'on donne au LLM" (bloc parent complet pour le contexte). Cela r√©sout le probl√®me de perte de contexte fr√©quent dans les RAG simples.
*   **Reranking & Cross-Encoders** : Comprendre le ph√©nom√®ne "Lost in the Middle" et pourquoi la recherche vectorielle bi-encoder manque parfois de pr√©cision fine. L'int√©gration d'un **Cross-Encoder** (BGE) m'a permis de r√©√©valuer la pertinence r√©elle des documents retrouv√©s avant l'√©tape de g√©n√©ration.
*   **Architecture Modulaire & Design Patterns** : Conception d'un pipeline flexible (Router, Loader, Retriever) permettant de changer de composants (ex: passer de ChromaDB √† PGVector) sans refondre le syst√®me.


## Choix Techniques & Alternatives

Un point cl√© de l'apprentissage a √©t√© l'arbitrage constant entre performance technique, co√ªt d'infrastructure et complexit√© de mise en ≈ìuvre.

### 1. Vision et Parsing de Documents : Le D√©fi des Tableaux
*   **Choix retenu : LlamaParse**
    *   *Pourquoi ?* C'est une solution sp√©cialis√©e qui reconstruit la structure des documents (tableaux, titres) en Markdown. Cela permet au LLM de "comprendre" la structure spatiale des donn√©es sans voir l'image.
*   **Alternative envisag√©e : LLM Multimodaux Vision**
    *   *Concept* : Envoyer directement les images des pages PDF au LLM pour qu'il "lise" visuellement le document.
    *   *Pourquoi pas ?* Bien que tr√®s performant, le **co√ªt aurait explos√©** pour de gros volumes documentaires. Un PDF de 100 pages trait√© page par page en vision est extr√™mement co√ªteux en tokens. LlamaParse offre un compromis "one-shot" beaucoup plus √©conomique et suffisant pour mon cas.

### 2. Mod√®le de Langage (Inf√©rence)
*   **D√©veloppement : Ollama (Local)**
    *   *Pourquoi ?* J'ai utilis√© **Ollama** pour faire tourner les mod√®les (Llama 3) enti√®rement en local pendant la phase de d√©veloppement. Cela m'a permis d'it√©rer rapidement sans co√ªt, sans latence r√©seau, et en gardant la ma√Ætrise totale de l'infrastructure.
*   **D√©ploiement Portfolio : Groq (Cloud)**
    *   *Pourquoi ?* Pour la d√©monstration publique, j'ai bascul√© sur l'API **Groq**. Son offre gratuite g√©n√©reuse et sa vitesse d'inf√©rence vous permet de tester le RAG avec une fluidit√©, sans que j'aie √† h√©berger un serveur GPU co√ªteux.

### 3. Base de Donn√©es Vectorielle
*   **Choix retenu : ChromaDB (Local)**
    *   *Pourquoi ?* Simplicit√© de mise en place (int√©gr√©), persistance locale sans Docker lourd -> prototypage rapide.


## L'Architecture Impl√©ment√©e

J'ai con√ßu une architecture modulaire pour r√©pondre aux probl√®mes courants des RAG basiques.

### 1. Ingestion Intelligente (Router & Parsing)
Le syst√®me utilise un **Router** pour diriger les fichiers :
*   **Pipeline Vision** : Traite les documents riches (tableaux, mises en page) via LlamaParse.
*   **Pipeline Texte** : Traite les textes simples via PyPDF pour la rapidit√©.

### 2. Recherche Hybride & Reranking
Pour pallier les faiblesses de la recherche s√©mantique (manque de pr√©cision sur les termes techniques) :
1.  **Ensemble Retriever** : Combine **BM25** (mots-cl√©s) + **ChromaDB** (vecteurs).
2.  **Reranker (BGE)** : R√©-ordonne les r√©sultats pour placer les plus pertinents en premier.

### 3. Chat & M√©moire
*   Gestion de l'historique de conversation (Stateful) via **PostgreSQL** (Dockeris√©).
*   Reformulation contextuelle des questions ("C'est quoi ?" devient "C'est quoi [le sujet pr√©c√©dent] ?").


## üõ† Stack Technique

**Backend & API**
*   **Python 3.10+** & **FastAPI** : Pour une API asynchrone robuste.
*   **PostgreSQL** : Base de donn√©es relationnelle (via Docker) pour la persistance des sessions.
*   **SQLAlchemy** : ORM pour l'interaction avec la BDD.

**Intelligence Artificielle**
*   **LangChain** : Framework d'orchestration.
*   **ChromaDB** : Stockage vectoriel.
*   **HuggingFace Embeddings** : `all-MiniLM-L6-v2` (bon ratio performance/vitesse).
*   **BAAI/bge-reranker** : Pour le reranking de pr√©cision.

**Outils**
*   **Docker** : Conteneurisation.
*   **LlamaParse** : OCR intelligent.
